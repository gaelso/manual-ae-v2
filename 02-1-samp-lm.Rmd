

# Sampling and stratification {#samp}


Sampling consists in predicting the characteristics of a set from one part (a sample) of this set. Typically, we want to estimate the volume of wood in a forest, but it is impossible to measure the volume of all the trees one by one. We therefore measure the volume of a sample of trees in the forest, then extrapolate to obtain an estimate for all the trees in the entire forest [p.252 @ctft89]. As volume is measured only in a sample of trees, the estimated total volume we obtain suffers from a *sampling error*^[The terms in italics are those used in sampling theory; a definition of these terms may be found, for example, in appendix 2 of @bellefontaine01.].
Sampling in the strict sense consists in:

1. selecting appropriate trees for the measured set (we tend to speak of a *sampling plan*),

2. selecting a method used to calculate total volume from the measurements (we tend to speak of an *estimator*),

in such a manner to minimize the sampling error.

In conventional sampling theory, the volumes of $N$ trees in the stand are fixed data: the only source of variation in the estimations is the sampling, such that exhaustive sampling would always give the same estimation. Here in this guide we will adopt the so-called super-population approach that was developed in the 1970s [@cochran77]. This consists in considering that the volumes of the $N$ trees that make up the stand are random variables, such that the observed stand is only one among others drawn from a super-population. This approach means that we can do away with certain approximations and draw up an optimal sampling plan (something that is often impossible in the conventional approach). It does, however, have the disadvantage of leading to incorrect solutions if the super-population model adopted does not comply with reality.

The sampling method depends on the goal. Therefore, in principle, the question must first be asked as to the purpose of the volume or biomass tables we are seeking to construct. Are they to serve to predict the characteristics of a particular tree that has known entry variables? Are they to serve to predict the characteristics of an average tree from data on entry variables? Are they to serve to predict the total volume of the stand that yielded the trees used to construct the tables, or the total volume of another stand? In both these latter cases, are the tables' entry variables measured in all the trees of the stand, or again on a sample of trees? Etc. We can therefore construct a chain that runs from the studied stand to the variable we are looking to predict (Figure \@ref(fig:cha)).

```{r cha, fig.cap="Chain running from the studied stand to the variables we are looking to predict."}

display_fig("cha")
  
```

By following this chain backward, it can be seen that the precision of the predicted variable depends on the precision of the tables' parameters, which itself depends on the sampling plan (number and selection of trees measured) and the variability within the studied stand [@cunia87c]. We can therefore set a target for the precision of our predictions which, by a retroactive effect for a given table and a given sampling type, determines the minimum number of trees to be measured. We can also apply an optimization procedure to determine, for a given target precision and a given table, the sampling method that minimizes measurement time or cost [@cunia87; @cunia87d]. In certain cases the cost of the measurements is the limiting factor. This in particular is the case for biomass measurements of root systems. Here in this case we are not looking so much to reach a given target precision in our prediction but to remain within reasonable cost limits. We can therefore, for a given measurement cost and a given type of table, determine the sampling plan that maximizes the precision of our predictions.

This reasoning, which is often too complex to be followed in a rigorous manner, should be applied on a case-by-case basis as it depends (*i*) on what we are looking to predict, (*ii*) on the type of tables used and (*iii*) on the type of sampling adopted. The fact that we are using a table is in itself a constraint on the sampling method: the total volume of a stand can be estimated from the volume of a sample of trees, without using volume tables. By using volume tables to estimate the total volume of a stand, we are already restricting ourselves to one type of total volume *estimator*.

What is more, the reasoning used to determine the sampling plan that complies with the target precision for our predictions assumes that we know the relation between the precision of our predictions and the precision of the parameters used to construct the tables, and the relation between the precision of the parameters used to construct the tables and sample size, etc. In certain simple cases these relations are explicitly known. But in most cases, as soon as the tables take a more complex form, these relations are not explicit. In this case, the above reasoning is no longer tractable.

This reasoning is delivered a knock-out blow when we realize that: (*i*) volume/biomass tables generally have multiple purposes or unspecified purposes and (*ii*) the form of these tables is generally unknown in advance. This is due to the simple fact that in most cases we wish to use these tables for different ends: to estimate the volume of a particular tree, an average tree, an entire stand, etc. Constructing the tables is ultimately an end in itself, without any reference to a quantity we wish to predict. Also, the form of the table is most often selected based on the results of an exploratory data analysis, and is therefore not known in advance. Obviously, some relationships such as the power function or second-order polynomials often recur, but no rule can be established *a priori*. It is therefore illusory to look to optimize a sampling plan.

Ultimately, the sampling used to construct volume/biomass tables is generally based on empirical considerations relating to the sampling plan. The choice of the *estimator*, which in fact determines which tables are chosen is made *a posteriori*, depending on the data collected, and independently of the sampling plan.





## Sampling for a simple linear regression {#simple}


Let us begin with a simple example that clearly illustrates the notions developed above. Let us assume that the trees in a given stand are described by their dbh $D$, their height $H$ and their volume $V$. We use volume tables that predict volume $V$ from the variable $D^2H$. The super-population model we adopt to describe the stand assumes that the relation between $V$ and $D^2H$ is linear, with white noise $\varepsilon$ of variance $\sigma^2$:
\begin{equation}
V=\alpha+\beta D^2H+\varepsilon(\#eq:MLex)
\end{equation}
where $\varepsilon$ follows a normal distribution of zero expectation and standard deviation $\sigma$. Let us also assume that the quantity $D^2H$ follows a normal distribution with a mean of $\mu$ and a standard deviation of $\tau$. White noise $\varepsilon$ incorporates all the factors that cause two trees of the same dbh and the same height not to have necessarily the same volume. Parameters
$\alpha$ and $\beta$ are unknown. To estimate them, we will measure 
$n$ trees; and will thus obtain a sample of $n$ doublets
$(D_1^2H_1,\ V_1),\ \ldots,\ (D_n^2H_n,\ V_n)$, then construct the following linear regression: 
\begin{equation}
V_i=a+b D_i^2H_i+\varepsilon_i(\#eq:reg)
\end{equation}
In sampling theory jargon, the entry variables for the volume/biomass tables (diameter, height $\ldots$) are called *auxiliary* variables. It is important to distinguish these tree-related variables from those such as age which are stand-related. These latter variables are considered as parameters [p.106 @parde88]. Also, the sampling *unit* is the tree. Let us now see how to draw up a sampling plan on the basis of the goal set.



### Predicting the volume of a particular tree

Let us assume that the goal is to predict the volume of a tree in a stand of dbh $D^*$ and height $H^*$. Its predicted volume is of course:
\[
V^*=a+b D^{*2}H^*
\]
The super-population model stipulates that because of white noise 
$\varepsilon$, two trees selected at random and with the same dbh $D$ and the same height $H$ do not necessarily have the same volume. This means we are faced with intrinsic variability when we measure a particular tree, equal to $\sigma^2$. When attempting to predict volumes, this intrinsic variability is supplemented by the variability due to the imprecision of the $\alpha$ and $\beta$ parameter estimations. We will return to these notions later (in Chapter \@ref(util)). Thus, for a linear regression, the semi-amplitude of the confidence interval at the threshold $\alpha$ (typically 5\ \%) of $V^*$ is equal to [p.374 @saporta90]:
\[
t_{n-2}\;\hat{\sigma} \sqrt{1+\frac{1}{n}+
\frac{(D^{*2}H^*-\overline{D^2H}_e)^2}{\sum_{i=1}^n(D_i^2H_i
-\overline{D^2H}_e)^2}}
\]
where $t_{n-2}$ is the quantile $1-\alpha/2$ of a Student's distribution with 
$n-2$ degrees of freedom, $\overline{D^2H}_e$ is the empirical mean of the $D^2H$ values measured in the sample:
\[
\overline{D^2H}_e=\frac{1}{n}\sum_{i=1}^nD_i^2H_i
\]
and $\hat{\sigma}$ is an estimate of the standard deviation of the residuals:
\[
\hat{\sigma}^2=\frac{1}{n-2}\sum_{i=1}^n[V_i-(a+b D_i^2H_i)]^2
\]
The lowest value of this semi-amplitude (when $n\rightarrow\infty$) is $1.96\ \sigma$. We will now set our precision target for the estimation as a deviation of $E\ \%$
from this incompressible minimum, i.e. in an approximate manner we are looking for sample size $n$
such that:
\begin{equation}
1 + E \approx \sqrt{
1 + \frac{1}{n} + \frac{(D^{*2}H^* - \overline{D^2H}_e)^2}{\sum_{i=1}^n(D_i^2H_i - \overline{D^2H}_e)^2}
}(\#eq:E1)
\end{equation}


#### Random sampling {-}

Let us first examine the case where we do not look to optimize the sampling plan, for example by selecting sample trees at random. The empirical mean of $D^2H$ in the sample is therefore an estimation of $\mu$, while the empirical variance of $D^2H$ in the sample is an estimation of $\tau^2$. Thus:
\[
(1+E)^2-1\approx\frac{1}{n}\left[
1+\frac{(D^{*2}H^*-\mu)^2}{\tau^2}\right]
\]
By way of a numerical example, let us take $\mu=5$ m^3^ as the mean value of $D^2H$ in the entire stand and $\tau=1$ m^3^
as its standard deviation. If we want to predict the volume of a tree that has a $D^2H$ of 2 m^3^ with a precision deviation of $E=5\ \%$, we will have to measure approximately $n=98$ trees.
We can see here that the expression of $n$ in relation to $D^{*2}H^*$
is symmetrical around $\mu$ and passes through a minimum for $D^{*2}H^*=\mu$. As $\mu-2=3$ m^3^ and $\mu+3=8$ m^3^, we will also need $n=98$ trees to predict the volume of a tree whose $D^2H$ is 8 m^3^ with a precision deviation of 5\ \%. The $n=98$ sample size may also be interpreted as that which ensures a precision deviation of at most 5\ \% (at $\alpha=5\ \%$) for all predictions in the 2--8 m^3^ range.


#### Optimized sampling {-}

Let us now examine the case where we are looking to optimize the sampling plan in relation to the value of $D^{*2}H^*$. Equation \@ref(eq:E1) shows that precision deviation $E$ is smallest when $\overline{D^2H}_e=D^{*2}H^*$. It is therefore advantageous to select sample trees in such a manner that their empirical mean $D^2H$ value is $D^{*2}H^*$. In practice, as the empirical mean of the sample's $D^2H$ values will never be exactly $D^{*2}H^*$, it is advantageous to maximize the denominator $\sum_i(D_i^2H_i-\overline{D^2H}_e)^2$, i.e. to maximize the empirical variance of the sample's $D^2H$ values. Ultimately, the sampling plan that maximizes the precision of the volume prediction of trees with $D^2H$ values of $D^{*2}H^*$ consists in selecting $n/2$ trees with $D^2H$ values of $D^{*2}H^*-\Delta$ and $n/2$ trees with $D^2H$ values of $D^{*2}H^*+\Delta$, with $\Delta$ being as large as possible (Figure \@ref(fig:plan)).


```{r plan, dev='tikz', cache=TRUE, fig.process = pdf2png, fig.align='center', out.width='100%', fig.scap="Sampling plan optimizing volume prediction precision for a particular tree", fig.cap="(ref:plan)"}

invisible(plot.new())
grid.raster(plan)
grid.text("$n/2$ trees", x = 0.15, y = 0.47)
grid.text("Volume?"    , x = 0.38, y = 0.53)
grid.text("$n/2$ trees", x = 0.72, y = 0.72)
grid.text("Size $D^2H$", x = 0.94, y = 0.3)
grid.text("$D^2H$"     , x = 0.38, y = 0.27)
grid.text("$\\Delta$"  , x = 0.25, y = 0.21)
grid.text("$\\Delta$"  , x = 0.5 , y = 0.21)

```

This sampling plan means that we can ignore the term dependent upon $D^{*2}H^*$ in Equation \@ref(eq:E1), thus simplifying the relationship to:
\[
(1+E)^2-1\approx\frac{1}{n}
\]
For $E=5\ \%$, this gives us $n=10$ trees. Optimizing the sampling plan has therefore "saved" us measuring 88 trees compared to the plan that consisted in selecting trees at random. However, the optimized plan is restricted to estimating the volume of a $D^{*2}H^*$sized tree. It is not optimized for estimating the volume of other sized trees. This reasoning therefore clearly has its limitations as volume tables are not generally (or even never) constructed to predict the volume of only one size of tree.

Even more seriously, the optimized sampling plan is also reliant upon the super-population model and may yield erroneous estimations if it does not correspond to reality. This is illustrated in Figure \@ref(fig:bad). The optimized sampling plan for a given $D^{*2}H^*$ size leads to the selection of extreme points (in black in Figure \@ref(fig:bad)) for the sample. This situation is critical for a linear regression as two groups of points far removed one from the other will give an elevated $R^2$ value without us really knowing what is happening between the two. If the linear relation assumed by the super-population model is correct (Figure \@ref(fig:bad) left), then there is no problem: the volume predicted by the tables (shown by a star) will indeed be close to the actual value (gray point). By contrast, if the super-population model is wrong, the predicted volume will be wrong: this is illustrated in Figure \@ref(fig:bad) on the right (where the sample points, in black, are exactly the same as those in Figure \@ref(fig:bad) on the left), where the size-volume relationship is in fact parabolic, not linear. In practice, the shape of the size-volume relationship (and therefore the volume tables) is not known in advance, and it is therefore best to sample trees across the entire size variation interval so as to visualize the nature of the size-volume relationship.

```{r bad, out.width=two_col, fig.scap="Volume prediction based on a linear regression constructed using extreme points when the size-volume relationship is indeed linear and when it is not", fig.cap="(ref:bad)"}

display_fig("badplan")

```



### Predicting the volume of a stand {#peup}

Let us now assume that the goal is to predict the volume of an entire stand. Here, we must first assume that we measure dbh $D$ and height $H$ in *all* the trees in the stand. Let $N$ be the number of trees in the stand (including the $n$ trees in the sample). Modulo renumbering of the trees therefore gives us a measurement of tree volume $V$ for $i=1,\ \ldots,\ n$ and a measurement of tree size $D^2H$ for $i=1,\ \ldots,\ N$. The estimator for the total volume of the stand deduced from the volume tables is therefore:
\[
V_{\scriptsize \mbox{tot}}=\sum_{i=1}^N(a+bD_i^2H_i)
\]
which may also be written: $V_{\scriptsize \mbox{tot}}=N\bar{V}$, where $\bar{V}=a+b\overline{D^2H}$ is the mean volume of the trees in the stand, and $\overline{D^2H}=(\sum_{i=1}^ND_i^2H_i)/N$ is the mean dbh of the trees in the stand. To the extent that the volume tables are obtained by linear regression of ($V_1,\ \ldots,\ V_n$) against ($D_1^2H_1,\ \ldots,\ D_n^2H_n$), the numerical values of the coefficients $a$ and $b$ verify [p.363 @saporta90]: $\bar{V}_e=a+b\overline{D^2H}_e$, where $\bar{V}_e=(\sum_{i=1}^nV_i)/n$ is the mean volume of the trees in the sample and $\overline{D^2H}_e=(\sum_{i=1}^nD_i^2H_i)/n$ is the mean size of the trees in the sample. By subtracting, we arrive at the following result:
\begin{equation}
\bar{V}=\bar{V}_e+b(\overline{D^2H}-\overline{D^2H}_e)(\#eq:est)
\end{equation}
In this equation it is important to note that $\bar{V}$ and $\overline{D^2H}$ are mean values for the entire stand while, $\bar{V}_e$ and $\overline{D^2H}_e$ are mean values for the sample. In addition $\overline{D^2H}$, $\overline{D^2H}_e$ and $\bar{V}_e$ are derived from actual measurement, while $\bar{V}$ is the quantity we are looking to estimate.

If we look at equation \@ref(eq:est), we recognize it as being a type of estimator that is widely used in sampling theory: the *regression estimators*. The theoretical basis of regression estimators is described in detail in Cochran [-@cochran77, chapter 7] and in Thompson [@thompson92, chapter 8]. A description of regression estimators used in forestry is given in @vries86 and in Shiver & Borders [-@shiver96 chapter 6] (the first is more theoretical, the second more applied). The theory of regression estimators applies in the case of a linear relationship between the quantity to be predicted ($\bar{V}$ in the example above) and an auxiliary variable ($\overline{D^2H}$ in the example above). By contrast, this theory is less well developed in the case of non-linear relations or multiple regressions, even though such cases often arise in connection with volume tables.

The semi-amplitude of the confidence interval at $\alpha$ (typically 5\ \%) of $\bar{V}$ is [@cochran77, p.199; @thompson92, p.83]:
\begin{equation}
t_{n-2}\;\hat{\sigma}\ \sqrt{\frac{1}{n}-\frac{1}{N}+
\frac{(\overline{D^2H}-\overline{D^2H}_e)^2}{\sum_{i=1}^n(D_i^2H_i
-\overline{D^2H}_e)^2}}(\#eq:icpop)
\end{equation}
It can be seen that the minimum of this amplitude is zero, that is reached when entire stand is included in the sample ($n=N$, that means that $\overline{D^2H}=\overline{D^2H}_e$). As before, the optimal sampling plan is such that $\overline{D^2H}_e$ is the closest possible to $\overline{D^2H}$, with a maximal empirical variance of $D^2H$ in the sample.

When deriving the regression estimator we assumed that size $D^2H$ is measured for *all* the trees in the stand in order to arrive at an estimation of total volume $V_{\scriptsize \mbox{tot}}$. In practice, a more realistic measurements protocol is as follows: the size of the trees in a sample of size $n'<N$ is measured; both size and volume are measured in a subsample of $n<n'$ of this sample. The volume vs dbh regression (i.e. the volume tables) is constructed using subsample values; this is then used to estimate the volume of the sample then, by extrapolation, that of the entire stand. This sampling strategy is called *double sampling*. Its theory is described in Cochran [-@cochran77, section 12.6] and, more pragmatically, in Shiver & Borders [-@shiver96, chapter 7]. Its use for estimating stand biomass was developed by @cunia87c; @cunia87; @cunia87d.

Finally, the properties of the regression estimator \@ref(eq:est) are well known in conventional sampling theory which does not require the hypothesis of a linear model \@ref(eq:MLex) but considers that the only source of variability is the sampling. In the case of a simple random sampling plan and a sufficiently large sample size $n$, the variance of $\bar{V}$ in conventional theory is approximately [@cochran77, p.195; @shiver96, p.181]:
\begin{equation}
\widehat{\mbox{Var}}(\bar{V})=\frac{1-n/N}{n(n-2)}\left\{
\sum_{i=1}^n(V_i-\bar{V}_e)^2-\frac{\left[\sum_{i=1}^n
(V_i-\bar{V}_e)(D_i^2H_i-\overline{D^2H}_e)\right]^2}{\sum_{i=1}^n
(D_i^2H_i-\overline{D^2H}_e)^2}\right\}(\#eq:VV)
\end{equation}
and the semi-amplitude confidence interval at $\alpha$ (typically 5\ \%) of $\bar{V}$ is approximately [p.80 @thompson92; p.185 @shiver96]:
\[
t_{n-2}\;\sqrt{\widehat{\mbox{Var}}(\bar{V})}
\]
This last expression is considered as being more robust than expression \@ref(eq:icpop) when the super-population model \@ref(eq:MLex) strays from reality [p.84 @thompson92].

In conclusion, this simple example shows both the advantages and limitations of sampling for the construction of volume tables: advantages because sampling theory provides us with the minimum number of trees that need to be measured to reach a given precision in our predictions, and thereby optimize the sampling plan; limitations because this reasoning assumes that the form of the volume tables (and that the underlying super-population model) is known in advance and that the tables will be used for a given application. Neither of these prerequisites is met in practice. Also, the calculations that are relatively simple in the case of the linear model we have just described rapidly become hopelessly complex for more realistic models.
