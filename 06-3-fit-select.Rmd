

## Selecting variables and models {#select}

When we look to construct a volume or biomass table, the graphical exploration of the data (chapter \@ref(explo)) generally yields several possible model forms. We could fit all these potentially interesting models, but ultimately, which of all these fitted models should be recommended to the user? Selecting variables and selecting models aims to determine which is the "best" possible expression of the model among all those fitted.


### Selecting variables

Let us take the example of a biomass table we are looking to construct from a dataset that includes tree diameter (dbh) and height, and wood specific density. By working on log-transformed data, and given the variables they include, we may fit the following models:

\begin{eqnarray*}
\ln(B) &=& a_0+a_1\ln(D)+\varepsilon\\ %
\ln(B) &=& a_0+a_2\ln(H)+\varepsilon\\ %
\ln(B) &=& a_0+a_3\ln(\rho)+\varepsilon\\ %
\ln(B) &=& a_0+a_1\ln(D)+a_2\ln(H)+\varepsilon\\ %
\ln(B) &=& a_0+a_1\ln(D)+a_3\ln(\rho)+\varepsilon\\ %
\ln(B) &=& a_0+a_2\ln(H)+a_3\ln(\rho)+\varepsilon\\ %
\ln(B) &=& a_0+a_1\ln(D)+a_2\ln(H)+a_3\ln(\rho)+\varepsilon
\end{eqnarray*}

The *complete* model (the last in the above list) is that which includes all the effect variables available. All the other models may be considered to be subsets of the complete model, but where certain effect variables have been employed and other set aside. Selecting the variables aims to choose --- from among the effect variables of the complete model --- those that should be kept and those that may be set aside as they contribute little to the prediction of the response variable. In other words, in this example, selecting the variables would consist in choosing the best model from among the seven models envisaged for $\ln(B)$.

Given that there are $p$ effect variables $X_1$, $X_2$, \ldots, $X_p$, there are $2^p-1$ models that include all or some of these effect variables. Selecting the variables consists in choosing the "best" combination of effect variables from all those available. This means firstly that we must have criterion that can be used to evaluate the quality of a model. We have already seen `r ifelse(book_format == "latex", "(p.\\pageref{irm}) ", "")`that $R^2$ is a poor criterion for evaluating the quality of one model in comparison with that of another as it increases automatically with the number of effect variables, and this regardless of whether these provide information useful for predicting the response variable or not. A better criterion for selecting effect variables is the residual variance estimator, which is linked to $R^2$ by the relation:
\[
\hat{\sigma}^2=\frac{n}{n-p-1}(1-R^2)\ S_Y^2
\]
where $S_Y^2$ is the empirical variance of the response variable.

Several methods may be used to select the best combination of effect variables. If $p$ is not too high, we can review all the $2^p-1$ possible models exhaustively. When $p$ is too high, a step by step method may be used to select the variables. Step-by-step methods proceed by the successive elimination or successive addition of effect variables. The descending method consists in eliminating the least significant of the $p$ variables. The regression is then recalculated and the process repeated until a stop criterion is satisfied (e.g. when all model coefficients are significantly different from zero). The ascending method proceeds in the opposite direction: we start with the best single-variable regression and add the variable that increases $R^2$ the most until the stop criterion is satisfied.

The so-called *stepwise* method is a further improvement upon the previous algorithm that consists in performing an additional Fisher's significance test at each step such as not to introduce a non-significant variable and possibly eliminate variables that have already been introduced but are no longer informative given the last variable selected. The algorithm stops when no more variables can be added or withdrawn. The different step-by-step selection methods do not necessarily give the same result, but the "stepwise" method would appear to be the best. They do not, however, safeguard from the untimely removal of variables that are actually significant, which may well bias the result. And in connection with this, it should be recalled that if we know (for biological reasons) why a variable should be included in a model (e.g. wood specific density), it is not because a statistical test declares it non-significant that it should be rejected (because of the test's type II error).

:::::::{.filrouge data-latex=""}

(@eq-selvar) (ref:selvar)

:::{.exercise #selvar name="(ref:selvar)"}
\  
:::

Let us select the variables $\ln(D)$, $[\ln(D)]^2$, $[\ln(D)]^3$, $\ln(H)$ to predict the log of the biomass. The complete model is therefore:
\[
\ln(B)=a_0+a_1\ln(D)+a_2[\ln(D)]^2+a_3[\ln(D)]^3+a_4\ln(H)
+\varepsilon
\]
where
\[
\mathrm{Var}(\varepsilon)=\sigma^2
\]
Variables are selected in R using the `step` command applied to the fitted complete model:

```{r, echo=T, results='hide'}
m <- lm(
  log(Btot) ~ I(log(dbh)) + I(log(dbh)^2) + I(log(dbh)^3) + I(log(heig)),
  data = dat[dat$Btot>0,]
  )
summary(step(m))
```

which yields:

```{r}
m <- lm(
  log(Btot) ~ I(log(dbh)^2) + I(log(heig)),
  data = dat[dat$Btot>0,]
  )
printCoefmat(summary(m)$coef, digits = 4, signif.stars = TRUE, signif.legend = FALSE)
```

The variables selected are therefore  $[\ln(D)]^2$ and $\ln(H)$. The model finally retained is therefore:
$\ln(B)=-6.50202+0.23756[\ln(D)]^2+1.01874\ln(H)$, with a residual standard deviation of `r print(summary(m)$sigma, digits = 4)` and $R^2=$ `r print(summary(m)$r.squared, digits = 4)`.

::::::


### Selecting models {#selmod}

Given two competitor models that predict the same response variable to within one transformation of a variable, which should we choose? Let us look at a few different cases before answering this question.

#### Nested models {-}

The simplest case is where the two models to be compared are nested. A model is *nested* in another if the two predict the same response variable and if we can move from the second to the first by removing one or several effect variables. For example, the biomass table $B=a_0+a_1D+\varepsilon$ is nested in $B=a_0+a_1D+a_2D^2H+\varepsilon$ since we can move from the second to the first by deleting $D^2H$ from the effect variables. Likewise, the model $B=a_0+a_2D^2H+\varepsilon$ is nested in $B=a_0+a_1D+a_2D^2H+\varepsilon$ since we can move from the second to the first by deleting $D$ from the effect variables. By contrast, the model $B=a_0+a_1D+\varepsilon$ is not nested in $B=a_0+a_2D^2H+\varepsilon$. Let $p$ be the number of effect variables in the complete model and $p'<p$ be the number of effect variables in the nested model. Without loss of generality, we can write the complete model as:

\begin{equation}
Y=f(X_1,\ \ldots,\ X_{p'},\ X_{p'+1},\ \ldots,\ X_p;
\theta_0,\ \theta_1)+\varepsilon(\#eq:embnl)
\end{equation}

where ($\theta_0$, $\theta_1$) is the vector of the coefficients associated with the complete model and $\theta_0$ is the vector of the coefficients associated with the nested model, which may be obtained by setting 
$\theta_1=\mathbf{0}$. In the particular case of the linear model, the complete model is obtained as the sum of the nested model and additional terms:

\begin{equation}
\underbrace{\underbrace{Y=a_0+a_1X_1+\ldots+a_{p'}X_{p'}}_{\mbox{\scriptsize
nested model}}+a_{p'+1}X_{p'+1}+\ldots+a_pX_p}_{\mbox{
\scriptsize complete model}}+\varepsilon(\#eq:emblm)
\end{equation}

where $\theta_0=(a_0,\ \ldots,\ a_{p'})$ and $\theta_1=(a_{p'+1},\ \ldots,\ a_p)$.

In the case of nested models, a statistical test can be used to test one of the models against the other. The null hypothesis of this test is that $\theta_1=\mathbf{0}$, i.e. the additional terms are not significant, which can also be expressed as: the nested model is better than the complete model. If the p-value of this test proves to be below the significance level (typically 5\ \%), then the null hypothesis is rejected, i.e. the complete model is best. Conversely, if the p-value is above the significance threshold, the nested model is considered to be the best.

In the case of the linear model \@ref(eq:emblm), the test statistic is a ratio of the mean squares, which under the null hypothesis follows Fisher's distribution. This is the same type of test as that used to test the overall significance of a multiple regression, or that used in the "stepwise" method of selecting variables. In the general case of the non-linear model \@ref(eq:embnl), the test statistic is a likelihood ratio, such that $-2\log$(likelihood ratio) under the null hypothesis follows a $\chi^2$ distribution.

::::::{.filrouge data-latex=""}

(@eq-fboite) (ref:fboite)

:::{.exercise #fboite name="(ref:fboite)"}
\  
:::

In red line \@ref(exr:selvar) the variable $[\ln(D)]^2$ was selected with $\ln(H)$ as effect variable of $\ln(B)$ but not $\ln(D)$. Model $\ln(B)=a_0+a_1\ln(D)+a_2[\ln(D)]^2+a_4\ln(H)$, which includes the additional term $\ln(D)$, can be compared with the model $\ln(B)=a_0+a_2[\ln(D)]^2+a_4\ln(H)$ using the nested models test. In R, the `anova` command can be used to test a nested model, with the first argument being the nested model and the second being the complete model:

```{r, echo=T, results='hide'}
comp <- lm(
  log(Btot) ~ I(log(dbh)) + I(log(dbh)^2) + I(log(heig)), 
  data=dat[dat$Btot > 0,]
  )
nest <- lm(
  log(Btot) ~ I(log(dbh)^2) + I(log(heig)), 
  data=dat[dat$Btot > 0,]
  )
anova(nest,comp)
```

The test gives the following result:

```{r}
res <- anova(nest, comp)
attr(res, "heading") <- NULL
res
```

The p-value is  `r print(res[2, "Pr(>F)"], digits = 4)`, therefore greater than 5\ \%. The nested model (without $\ln(D)$) is therefore selected rather than the complete model.

::::::

::::::{.filrouge data-latex=""}


\begin{filrouge}{Testing nested models: $\ln(H)$}{fboite2}%
The model $\ln(B)=-\decimal{8}{42722}+\decimal{2}{36104}\ln(D)$ was obtained in red line \@ref(exr:rllnBvD) whereas red line \@ref(exr:flnDlnH) gave the model $\ln(B)=-\decimal{8}{9050}+\decimal{1}{8654}\ln(D)+\decimal{0}{7083}\ln(H)$. As the first is nested in the second, we can test for which is the best. The command 
\R{comp <- lm(log(Btot)$\sim$I(log(dbh))+I(log(heig)),data=dat[dat\$Btot>0,])%
\\ nest <- lm(log(Btot)$\sim$I(log(dbh)),data=dat[dat\$Btot>0,])%
\\ anova(nest,comp)}%
yields:
\Rout{\begin{tabular}{lrrrrrrl}%
  & Res.Df &    RSS & Df & Sum of Sq &      F &   Pr(>F) &   \\ %
1 &     39 & 8.3236 &    &           &        &          &   \\ %
2 &     38 & 6.4014 &  1 &    1.9222 & 11.410 & 0.001698 & **\\ %
\end{tabular}}%
As the p-value is less than 5\ \%, the complete model (including $\ln(H)$ as effect variable) is selected rather than the nested model.

\end{filrouge}

#### Models with the same response variable

